### 生产者优化

​		实际环境中只使用一个用户主线程通常无法满足所需的吞吐量目标，因此需要构造多个线程和多个进程来同时给Kafka集群发消息。本次优化基于多线程单例Kafka，这种方法就是在全局构造一个KafkaProducer实例，然后在多个线程中共享使用。

```
多线程 单例afkaProducer参考博客
https://www.cnblogs.com/superfj/p/9440835.html
线程池参考博客
https://www.jianshu.com/p/f030aa5d7a28
```

生产者线程

```
package com.bupt.producer.com.bupt.producer;

import org.apache.kafka.clients.producer.Callback;
import org.apache.kafka.clients.producer.KafkaProducer;
import org.apache.kafka.clients.producer.ProducerRecord;
import org.apache.kafka.clients.producer.RecordMetadata;

/**
 * 生产者线程
 */
public class ProducerThread implements Runnable {

    private KafkaProducer<String, String> producer = null;
    private ProducerRecord<String, String> record = null;

    public ProducerThread(KafkaProducer<String, String> producer, ProducerRecord<String, String> record) {
        this.producer = producer;
        this.record = record;
    }

    @Override
    public void run() {
        producer.send(record, new Callback() {
            @Override
            public void onCompletion(RecordMetadata  metadata, Exception e) {
                if( null != e){
                    e.printStackTrace();
                }
                else{
                    System.out.println("消息发送成功 ：         "+String.format("offset: %s, partition:%s, topic:%s  timestamp:%s",
                     metadata.offset(), metadata.partition(), metadata.topic(), metadata.timestamp()));
                }
            }
        });
    }

}
```

线程池生产者

```
package com.bupt.producer.com.bupt.producer;
import org.apache.kafka.clients.producer.*;
import org.apache.kafka.clients.producer.ProducerConfig;

import java.util.Properties;
import java.util.UUID;
import java.util.concurrent.*;
//多线程 单例afkaProducer参考博客
// 参考 https://www.cnblogs.com/superfj/p/9440835.html
//线程池参考博客
//https://www.jianshu.com/p/f030aa5d7a28
/**
 * 线程池生产者
 *
 */
public class ProducerDemo {
    static Properties properties = new Properties();

    static String topic = "first";

    static KafkaProducer<String, String> producer = null;

    // 核心池大小
    static int corePoolSize = 5;

    // 最大值
    static int maximumPoolSize = 20;

    // 无任务时存活时间
    static long keepAliveTime = 60;

    // 时间单位
    static TimeUnit timeUnit = TimeUnit.SECONDS;

    // 阻塞队列
    static BlockingQueue blockingQueue = new LinkedBlockingQueue();

    // 线程池
    static ExecutorService service = null;

    static {
        // 配置项
        properties.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, "hadoop101:9092");
        properties.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, "org.apache.kafka.common.serialization.StringSerializer");
        properties.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, "org.apache.kafka.common.serialization.StringSerializer");
        producer = new KafkaProducer<String, String>(properties);
        // 初始化线程池
        service = new ThreadPoolExecutor(corePoolSize, maximumPoolSize, keepAliveTime, timeUnit, blockingQueue);
    }

    public static void main(String args[]) throws Exception {
        for (int i = 0; i < 20; i++) {
            ProducerRecord<String, String> record = new ProducerRecord<String, String>(topic, "hello yk "+i);
            ProducerThread task = new ProducerThread(producer, record);
            service.submit(task);
        }
    }


  }


```

